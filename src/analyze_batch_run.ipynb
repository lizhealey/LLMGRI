{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adfc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = 'Final_results'\n",
    "\n",
    "datasets = ['CIQ','MDI','CSII']\n",
    "datasets = ['MDI','CSII','CIQ']\n",
    "prompt_type = 'Metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca74cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{name}/all_dict.pkl', 'rb') as f:\n",
    "    all_dict= pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa1621",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a703f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f910d",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43968b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = ['MDI','CSII','CIQ']\n",
    "prompt_type = 'Metric'\n",
    "models = [\"gpt-3.5-turbo-0125\", \"gpt-4.1-2025-04-14\", \"o4-mini-2025-04-16\"]\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    stats = get_stats(dataset)\n",
    "    model_dict = {}\n",
    "    for model in models:\n",
    "        print('#'*20)\n",
    "        print(model)\n",
    "        try:\n",
    "            batch_dir =f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "            \n",
    "            \n",
    "            outcomes_df, _,_ = get_percentiles_fixed(batch_dir)#.set_index('number')\n",
    "            outcomes_df = outcomes_df.set_index('number')\n",
    "            df = stats.merge(outcomes_df,left_index = True,right_index=True)\n",
    "            \n",
    "            model_title = names[model]\n",
    "            model_dict[model_title] = df\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "                \n",
    "    all_dict[dataset]=model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1dec6e",
   "metadata": {},
   "source": [
    "### Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660eb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Final_results_reversed'\n",
    "prompt_type = 'Metric'\n",
    "models = ['claude-3-haiku-20240307','claude-3-7-sonnet-20250219',]\n",
    "datasets = ['MDI','CSII','CIQ']\n",
    "\n",
    "for dataset in datasets:\n",
    "    stats = get_stats(dataset)\n",
    "    for model in models:\n",
    "            try:\n",
    "                batch_dir =f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "                \n",
    "                \n",
    "                outcomes_df, win_df,df = get_percentiles_fixed(batch_dir)\n",
    "                outcomes_df = outcomes_df.set_index('number')\n",
    "                df = stats.merge(outcomes_df,left_index = True,right_index=True)\n",
    "                model_title = names[model]\n",
    "                print(model_title)\n",
    "                all_dict[dataset][model_title] = df\n",
    "            except Exception as e:\n",
    "                print(\"An error occurred:\", e)\n",
    "                print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e098643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'{name}/all_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(all_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a4750",
   "metadata": {},
   "source": [
    "# Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gri_tir_dual_axis_fixed_scale(all_dict, datasets, correlation_type='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e5e14",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coeffs = [3, 2.4, .8, 1.6] \n",
    "dataset = 'CIQ'\n",
    "datasets = ['MDI','CSII','CIQ']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_regression_coefficients_sm(datasets, all_dict, true_coeffs, scaled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d8d2b",
   "metadata": {},
   "source": [
    "# Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5174aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-3.5-turbo-0125', 'gpt-4.1-2025-04-14', 'o4-mini-2025-04-16','claude-3-haiku-20240307','claude-3-7-sonnet-20250219',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "model_decisions = {}\n",
    "\n",
    "concordance_matrices = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    first = True\n",
    "    model_decisions = {}\n",
    "    for model in models:\n",
    "        \n",
    "            \n",
    "        batch_dir = f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "        with open(f\"{batch_dir}/outputs.p\", \"rb\") as f:\n",
    "            outputs = pickle.load(f)\n",
    "\n",
    "        _, win_df, df = get_percentiles_fixed(batch_dir)\n",
    "\n",
    "\n",
    "        if first == True:\n",
    "            df[['id1', 'id2']] = df['pair'].str.split('_', expand=True)\n",
    "            temp_model = 'o4-mini' \n",
    "            for index, row in df.iterrows():\n",
    "                id1 = int(row['id1'])\n",
    "                id2 = int(row['id2'])\n",
    "                gri1 = all_dict[dataset][temp_model].loc[id1, 'GRI']\n",
    "                gri2 = all_dict[dataset][temp_model].loc[id2, 'GRI']\n",
    "                if gri1 < gri2:\n",
    "                    df.at[index, 'lower_GRI'] = id1\n",
    "                else:\n",
    "                    df.at[index, 'lower_GRI'] = id2\n",
    "                # go through win df and make column with higher TIR\n",
    "                tir1 = all_dict[dataset][temp_model].loc[id1, 'TIR']\n",
    "                tir2 = all_dict[dataset][temp_model].loc[id2, 'TIR']\n",
    "                if tir1 > tir2:\n",
    "                    df.at[index, 'higher_TIR'] = id1\n",
    "                else:\n",
    "                    df.at[index, 'higher_TIR'] = id2\n",
    "\n",
    "            model_decisions['GRI'] = df.set_index('pair')['lower_GRI']\n",
    "            model_decisions['TIR'] = df.set_index('pair')['higher_TIR']\n",
    "            first = False\n",
    "        model_decisions[names[model]] = df.set_index('pair')['winner']\n",
    "\n",
    "    models_list = list(model_decisions.keys())\n",
    "    concordance_matrix = pd.DataFrame(index=models_list, columns=models_list, dtype=float)\n",
    "\n",
    "    for m1, m2 in combinations(models_list, 2):\n",
    "        s1 = model_decisions[m1]\n",
    "        s2 = model_decisions[m2]\n",
    "        \n",
    "        common_pairs = s1.index.intersection(s2.index)\n",
    "        if len(common_pairs) == 0:\n",
    "            concordance = np.nan\n",
    "        else:\n",
    "            concordance = (s1.loc[common_pairs] == s2.loc[common_pairs]).mean()\n",
    "        \n",
    "        concordance_matrix.loc[m1, m2] = concordance\n",
    "        concordance_matrix.loc[m2, m1] = concordance\n",
    "\n",
    "    np.fill_diagonal(concordance_matrix.values, 1.0)\n",
    "\n",
    "    concordance_matrix = concordance_matrix.round(3)\n",
    "    concordance_matrices.append(concordance_matrix)\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(18, 4), dpi=150)\n",
    "gs = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.05])\n",
    "axes = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "cbar_ax = fig.add_subplot(gs[3])\n",
    "\n",
    "heatmaps = []\n",
    "for i, ax in enumerate(axes):\n",
    "    mask = np.tril(np.ones_like(concordance_matrices[i], dtype=bool), k=-1)  \n",
    "    hm = sns.heatmap(\n",
    "        concordance_matrices[i].astype(float),\n",
    "        annot=True,\n",
    "        cmap=\"Blues\",\n",
    "        fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "        cbar=False,  \n",
    "        ax=ax, mask =mask\n",
    "    )\n",
    "    ax.set_title(f\"{datasets[i]} Concordance\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "    ax.grid(False)\n",
    "    \n",
    "    for idx in range(concordance_matrices[i].shape[0]):\n",
    "        axes[i].add_patch(\n",
    "            plt.Rectangle((idx, idx), 1, 1, fill=True, color='lightgrey', lw=0, zorder=3)\n",
    "        )\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    heatmaps.append(hm)\n",
    "\n",
    "fig.colorbar(heatmaps[-1].collections[0], cax=cbar_ax)\n",
    "cbar_ax.set_ylabel(\"Concordance\", rotation=270, labelpad=15)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.7)  \n",
    "plt.savefig(\"Figures/all_datasets_concordance.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb41e638",
   "metadata": {},
   "source": [
    "# Case Studies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd391d56",
   "metadata": {},
   "source": [
    "## Case studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d328b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "var = 'both'\n",
    "datasets = ['CSII']  \n",
    "\n",
    "for dataset in datasets:\n",
    "    stats = get_stats(dataset)\n",
    "    \n",
    "    model_dfs = {}\n",
    "    model_pairs = {}\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        name = 'Final_results'\n",
    "        batch_dir = f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "        outcomes_df, win_df, pair = get_percentiles_fixed(batch_dir)\n",
    "        outcomes_df = outcomes_df.set_index('number')\n",
    "        df = stats.merge(outcomes_df,left_index=True,right_index=True)\n",
    "        \n",
    "        model_dfs[model] = df\n",
    "        model_pairs[model] = pair\n",
    "\n",
    "    first_model = models[0]\n",
    "    df = model_dfs[first_model]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15382351",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting_pairs = []\n",
    "for pr in [(27,97),(58,100)]:\n",
    "    idx1, idx2 = pr\n",
    "    row1 = df.loc[idx1]\n",
    "    row2 = df.loc[idx2]\n",
    "\n",
    "    model_votes = {}\n",
    "    for model in models:\n",
    "        pair_df = model_pairs[model]\n",
    "        pair_id1 = f\"{idx1}_{idx2}\"\n",
    "        pair_id2 = f\"{idx2}_{idx1}\"\n",
    "        winner = None\n",
    "        if pair_id1 in pair_df['pair'].values:\n",
    "            winner = pair_df[pair_df['pair'] == pair_id1]['winner'].values[0]\n",
    "        elif pair_id2 in pair_df['pair'].values:\n",
    "            winner = pair_df[pair_df['pair'] == pair_id2]['winner'].values[0]\n",
    "            flag ==True\n",
    "        \n",
    "        model_votes[model] = int(winner)\n",
    "    votes = [vote for vote in model_votes.values()]\n",
    "   \n",
    "    conflicting_pairs.append(pr)\n",
    "    print(\"Model votes:\", model_votes)\n",
    "\n",
    "    plot_two_cases_with_votes(row1, row2, model_votes,  dataset, idx1, idx2,model_dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
