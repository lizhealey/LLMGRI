{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "from utils.utils import *\n",
    "from utils.openai_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0bd34e",
   "metadata": {},
   "source": [
    "# Send to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = 'CSII'\n",
    "\n",
    "prompt_type = 'Metric'\n",
    "\n",
    "model ='gpt-3.5-turbo-0125'\n",
    "model =\"o4-mini-2025-04-16\"\n",
    "\n",
    "strings = generate_tir_dict()\n",
    "   \n",
    "individual_data = load_data_metrics_for_prompt_short(dataset) \n",
    "prompt_list = {}\n",
    "for (hypo, hyper,tir), description in strings.items():\n",
    "    for id in individual_data:\n",
    "\n",
    "        pat = individual_data[id]\n",
    "        comparator = description\n",
    "\n",
    "        prompt_list[(hypo, hyper,tir,id)] = instructions(comparator,pat)\n",
    "\n",
    "\n",
    "for model in [model]:\n",
    "\n",
    "    batch_dir =f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "    os.makedirs(batch_dir, exist_ok=True)\n",
    "    \n",
    "   \n",
    "    batch_json = make_batch_json(prompt_list, batch_dir )\n",
    "\n",
    "    # Make the input file\n",
    "    client = OpenAI()\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(batch_json, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    save_input_file_openai(batch_input_file, batch_dir, batch_json)\n",
    "    \n",
    "\n",
    "    client = OpenAI()\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_sent= client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/responses\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"{model}_{dataset}_{datetime.now().strftime('%Y_%m_%d_%Hh')}\"\n",
    "        }\n",
    "    )\n",
    "    save_batch_file_openai(batch_sent, batch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_type = 'Metric'\n",
    "\n",
    "name = \"Batch_perturbation\"\n",
    "dataset = 'CSII'\n",
    "\n",
    "batch_dir =f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "os.makedirs(batch_dir, exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models =['gpt-3.5-turbo-0125',\"o4-mini-2025-04-16\"]\n",
    "for model in models:\n",
    "    batch_dir =f\"{name}/{dataset}/{prompt_type}/{model}/\"\n",
    "    batch_metadata = load_batch_file_openai(batch_dir)\n",
    "    batch =client.batches.retrieve(batch_metadata['batch_id'])\n",
    "    print(batch)\n",
    "    save_batch_file_openai(batch, batch_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
